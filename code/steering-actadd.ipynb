{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8522291,"datasetId":5033075,"databundleVersionId":8664816},{"sourceType":"datasetVersion","sourceId":8458525,"datasetId":5035684,"databundleVersionId":8597365}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install -q -U torch transformers matplotlib pandas scikit-learn seaborn datasets\nimport torch \nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom tqdm import tqdm\nimport json\nimport os\nfrom datetime import datetime\nfrom glob import glob\nimport torch.nn.functional as F\nimport random\nfrom collections import defaultdict\nfrom enhanced_hooking import get_activations, add_activations_and_generate, clear_hooks, get_activations_and_generate\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datasets import load_dataset\n%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:42:59.638334Z","iopub.execute_input":"2024-05-26T13:42:59.638964Z","iopub.status.idle":"2024-05-26T13:43:01.484936Z","shell.execute_reply.started":"2024-05-26T13:42:59.638935Z","shell.execute_reply":"2024-05-26T13:43:01.484138Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#### Load the model\ndef load_model(model_path, device, center_weights=True):\n    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16 if '13b' in model_path else torch.float32, token=HF_TOKEN).to(device)#, torch_dtype=torch.float16\n    if center_weights:\n        for name, param in model.named_parameters():\n            if '.'.join(name.split('.')[-2:]) in ['wte.weight','wpe.weight','c_proj.weight','c_proj.bias']:\n                param.data -= param.data.mean()\n                print(name, param.data.mean(), param.size())\n    tokenizer = AutoTokenizer.from_pretrained(model_path, token=HF_TOKEN)\n    model.tokenizer = tokenizer\n    #model.tokenizer.padding_side = \"left\" #for batching; right (default in gpt2) for training, left for generation\n    model.tokenizer.pad_token_id = model.tokenizer.eos_token_id \n    return model\n\nmodel=None\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n_ = torch.set_grad_enabled(False)\nmodel_path: str = \"gpt2-xl\" #even on an A40 I have to load 13b in half precision\ndevice: str = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\" #need to upgrade MacOS first\n#device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncenter_weights=True\n\nmodel = load_model(model_path, device, center_weights=center_weights)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T15:12:15.930296Z","iopub.execute_input":"2024-05-26T15:12:15.931060Z","iopub.status.idle":"2024-05-26T15:12:22.441230Z","shell.execute_reply.started":"2024-05-26T15:12:15.931028Z","shell.execute_reply":"2024-05-26T15:12:22.440314Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"transformer.wte.weight tensor(-4.9907e-10, device='cuda:0') torch.Size([50257, 1600])\ntransformer.wpe.weight tensor(-5.5879e-11, device='cuda:0') torch.Size([1024, 1600])\ntransformer.h.0.attn.c_proj.weight tensor(8.8895e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.0.attn.c_proj.bias tensor(-7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.0.mlp.c_proj.weight tensor(1.2740e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.0.mlp.c_proj.bias tensor(-2.4214e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.1.attn.c_proj.weight tensor(3.7402e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.1.attn.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.1.mlp.c_proj.weight tensor(4.0233e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.1.mlp.c_proj.bias tensor(0., device='cuda:0') torch.Size([1600])\ntransformer.h.2.attn.c_proj.weight tensor(-3.7253e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.2.attn.c_proj.bias tensor(4.4703e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.2.mlp.c_proj.weight tensor(-1.4156e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.2.mlp.c_proj.bias tensor(5.9605e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.3.attn.c_proj.weight tensor(-1.6689e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.3.attn.c_proj.bias tensor(1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.3.mlp.c_proj.weight tensor(3.3453e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.3.mlp.c_proj.bias tensor(1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.4.attn.c_proj.weight tensor(1.1623e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.4.attn.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.4.mlp.c_proj.weight tensor(8.5309e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.4.mlp.c_proj.bias tensor(5.5879e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.5.attn.c_proj.weight tensor(1.9073e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.5.attn.c_proj.bias tensor(-1.8626e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.5.mlp.c_proj.weight tensor(-4.1723e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.5.mlp.c_proj.bias tensor(0., device='cuda:0') torch.Size([1600])\ntransformer.h.6.attn.c_proj.weight tensor(3.4571e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.6.attn.c_proj.bias tensor(-3.7253e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.6.mlp.c_proj.weight tensor(6.7055e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.6.mlp.c_proj.bias tensor(2.6077e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.7.attn.c_proj.weight tensor(-1.5497e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.7.attn.c_proj.bias tensor(2.2352e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.7.mlp.c_proj.weight tensor(3.3379e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.7.mlp.c_proj.bias tensor(9.3132e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.8.attn.c_proj.weight tensor(-4.3213e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.8.attn.c_proj.bias tensor(7.4506e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.8.mlp.c_proj.weight tensor(-1.2740e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.8.mlp.c_proj.bias tensor(3.1665e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.9.attn.c_proj.weight tensor(3.5763e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.9.attn.c_proj.bias tensor(3.9116e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.9.mlp.c_proj.weight tensor(-1.0356e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.9.mlp.c_proj.bias tensor(7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.10.attn.c_proj.weight tensor(-3.3379e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.10.attn.c_proj.bias tensor(1.7695e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.10.mlp.c_proj.weight tensor(2.0862e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.10.mlp.c_proj.bias tensor(1.0245e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.11.attn.c_proj.weight tensor(-2.5779e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.11.attn.c_proj.bias tensor(-1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.11.mlp.c_proj.weight tensor(1.4976e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.11.mlp.c_proj.bias tensor(-1.8626e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.12.attn.c_proj.weight tensor(-3.8743e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.12.attn.c_proj.bias tensor(-3.7253e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.12.mlp.c_proj.weight tensor(-5.5730e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.12.mlp.c_proj.bias tensor(-1.6764e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.13.attn.c_proj.weight tensor(-4.4927e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.13.attn.c_proj.bias tensor(5.1688e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.13.mlp.c_proj.weight tensor(-1.4752e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.13.mlp.c_proj.bias tensor(0., device='cuda:0') torch.Size([1600])\ntransformer.h.14.attn.c_proj.weight tensor(5.6326e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.14.attn.c_proj.bias tensor(-1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.14.mlp.c_proj.weight tensor(-2.6263e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.14.mlp.c_proj.bias tensor(-4.8429e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.15.attn.c_proj.weight tensor(1.8179e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.15.attn.c_proj.bias tensor(1.8626e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.15.mlp.c_proj.weight tensor(1.6689e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.15.mlp.c_proj.bias tensor(-2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.16.attn.c_proj.weight tensor(-6.2585e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.16.attn.c_proj.bias tensor(1.3039e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.16.mlp.c_proj.weight tensor(-5.2825e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.16.mlp.c_proj.bias tensor(-2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.17.attn.c_proj.weight tensor(-2.8908e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.17.attn.c_proj.bias tensor(-3.7253e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.17.mlp.c_proj.weight tensor(3.7178e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.17.mlp.c_proj.bias tensor(-4.4703e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.18.attn.c_proj.weight tensor(1.6540e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.18.attn.c_proj.bias tensor(-7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.18.mlp.c_proj.weight tensor(-3.2410e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.18.mlp.c_proj.bias tensor(-1.8626e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.19.attn.c_proj.weight tensor(7.5996e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.19.attn.c_proj.bias tensor(5.5879e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.19.mlp.c_proj.weight tensor(-2.9746e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.19.mlp.c_proj.bias tensor(-7.4506e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.20.attn.c_proj.weight tensor(-4.4703e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.20.attn.c_proj.bias tensor(1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.20.mlp.c_proj.weight tensor(4.4033e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.20.mlp.c_proj.bias tensor(0., device='cuda:0') torch.Size([1600])\ntransformer.h.21.attn.c_proj.weight tensor(-7.6294e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.21.attn.c_proj.bias tensor(1.3039e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.21.mlp.c_proj.weight tensor(-4.4852e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.21.mlp.c_proj.bias tensor(-3.7253e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.22.attn.c_proj.weight tensor(3.2783e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.22.attn.c_proj.bias tensor(2.2352e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.22.mlp.c_proj.weight tensor(5.6252e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.22.mlp.c_proj.bias tensor(7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.23.attn.c_proj.weight tensor(-4.5300e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.23.attn.c_proj.bias tensor(3.3528e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.23.mlp.c_proj.weight tensor(-6.9290e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.23.mlp.c_proj.bias tensor(-1.1176e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.24.attn.c_proj.weight tensor(5.2452e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.24.attn.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.24.mlp.c_proj.weight tensor(-2.6897e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.24.mlp.c_proj.bias tensor(5.9605e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.25.attn.c_proj.weight tensor(4.3213e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.25.attn.c_proj.bias tensor(7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.25.mlp.c_proj.weight tensor(7.5996e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.25.mlp.c_proj.bias tensor(1.1176e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.26.attn.c_proj.weight tensor(-5.6773e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.26.attn.c_proj.bias tensor(2.1420e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.26.mlp.c_proj.weight tensor(2.0918e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.26.mlp.c_proj.bias tensor(1.8626e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.27.attn.c_proj.weight tensor(-4.2319e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.27.attn.c_proj.bias tensor(7.0781e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.27.mlp.c_proj.weight tensor(2.0787e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.27.mlp.c_proj.bias tensor(2.6077e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.28.attn.c_proj.weight tensor(-7.1526e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.28.attn.c_proj.bias tensor(3.5390e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.28.mlp.c_proj.weight tensor(-2.9802e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.28.mlp.c_proj.bias tensor(1.8626e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.29.attn.c_proj.weight tensor(4.3809e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.29.attn.c_proj.bias tensor(-2.0489e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.29.mlp.c_proj.weight tensor(2.7567e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.29.mlp.c_proj.bias tensor(-4.2841e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.30.attn.c_proj.weight tensor(2.6822e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.30.attn.c_proj.bias tensor(-9.3132e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.30.mlp.c_proj.weight tensor(3.2783e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.30.mlp.c_proj.bias tensor(1.8626e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.31.attn.c_proj.weight tensor(-3.6359e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.31.attn.c_proj.bias tensor(-7.4506e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.31.mlp.c_proj.weight tensor(6.1318e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.31.mlp.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.32.attn.c_proj.weight tensor(1.3113e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.32.attn.c_proj.bias tensor(3.7253e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.32.mlp.c_proj.weight tensor(5.3197e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.32.mlp.c_proj.bias tensor(2.7940e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.33.attn.c_proj.weight tensor(2.6375e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.33.attn.c_proj.bias tensor(7.1712e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.33.mlp.c_proj.weight tensor(2.6822e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.33.mlp.c_proj.bias tensor(-2.6077e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.34.attn.c_proj.weight tensor(1.9073e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.34.attn.c_proj.bias tensor(-1.1176e-09, device='cuda:0') torch.Size([1600])\ntransformer.h.34.mlp.c_proj.weight tensor(-5.7220e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.34.mlp.c_proj.bias tensor(-4.6566e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.35.attn.c_proj.weight tensor(6.4373e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.35.attn.c_proj.bias tensor(3.3528e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.35.mlp.c_proj.weight tensor(-2.5630e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.35.mlp.c_proj.bias tensor(1.1176e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.36.attn.c_proj.weight tensor(6.4373e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.36.attn.c_proj.bias tensor(1.1176e-09, device='cuda:0') torch.Size([1600])\ntransformer.h.36.mlp.c_proj.weight tensor(1.6838e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.36.mlp.c_proj.bias tensor(2.4214e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.37.attn.c_proj.weight tensor(-4.8280e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.37.attn.c_proj.bias tensor(-5.5879e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.37.mlp.c_proj.weight tensor(4.8280e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.37.mlp.c_proj.bias tensor(-2.2352e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.38.attn.c_proj.weight tensor(2.0862e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.38.attn.c_proj.bias tensor(1.3411e-09, device='cuda:0') torch.Size([1600])\ntransformer.h.38.mlp.c_proj.weight tensor(2.5332e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.38.mlp.c_proj.bias tensor(-1.4901e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.39.attn.c_proj.weight tensor(3.8743e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.39.attn.c_proj.bias tensor(1.8626e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.39.mlp.c_proj.weight tensor(2.9802e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.39.mlp.c_proj.bias tensor(-1.0803e-09, device='cuda:0') torch.Size([1600])\ntransformer.h.40.attn.c_proj.weight tensor(-2.2650e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.40.attn.c_proj.bias tensor(2.2352e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.40.mlp.c_proj.weight tensor(1.4007e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.40.mlp.c_proj.bias tensor(4.4703e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.41.attn.c_proj.weight tensor(-3.3081e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.41.attn.c_proj.bias tensor(0., device='cuda:0') torch.Size([1600])\ntransformer.h.41.mlp.c_proj.weight tensor(-2.4289e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.41.mlp.c_proj.bias tensor(-6.3330e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.42.attn.c_proj.weight tensor(3.7849e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.42.attn.c_proj.bias tensor(3.5390e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.42.mlp.c_proj.weight tensor(7.1526e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.42.mlp.c_proj.bias tensor(3.7253e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.43.attn.c_proj.weight tensor(-3.2187e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.43.attn.c_proj.bias tensor(3.7253e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.43.mlp.c_proj.weight tensor(-1.4156e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.43.mlp.c_proj.bias tensor(-2.4214e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.44.attn.c_proj.weight tensor(-1.7881e-11, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.44.attn.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.44.mlp.c_proj.weight tensor(5.9903e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.44.mlp.c_proj.bias tensor(2.9802e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.45.attn.c_proj.weight tensor(-2.8908e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.45.attn.c_proj.bias tensor(5.2154e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.45.mlp.c_proj.weight tensor(8.7172e-11, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.45.mlp.c_proj.bias tensor(-7.4506e-11, device='cuda:0') torch.Size([1600])\ntransformer.h.46.attn.c_proj.weight tensor(2.5332e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.46.attn.c_proj.bias tensor(5.9605e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.46.mlp.c_proj.weight tensor(-1.5646e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.46.mlp.c_proj.bias tensor(1.6764e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.47.attn.c_proj.weight tensor(4.7088e-10, device='cuda:0') torch.Size([1600, 1600])\ntransformer.h.47.attn.c_proj.bias tensor(4.4703e-10, device='cuda:0') torch.Size([1600])\ntransformer.h.47.mlp.c_proj.weight tensor(5.8077e-10, device='cuda:0') torch.Size([6400, 1600])\ntransformer.h.47.mlp.c_proj.bias tensor(-7.8231e-10, device='cuda:0') torch.Size([1600])\n","output_type":"stream"}]},{"cell_type":"code","source":"#1-off testing: capture activations\nclear_hooks(model)\nbehavior_pos_prompt = model.tokenizer.bos_token+\"Love\"#\"Fishing\" #\"You are very agreeable\"\nbehavior_neg_prompt = model.tokenizer.bos_token+\"Hate\"#\"\" #\"You are very disagreeable\"\ntokens_pos = model.tokenizer.encode(behavior_pos_prompt, return_tensors=\"pt\")\ntokens_neg = model.tokenizer.encode(behavior_neg_prompt, return_tensors=\"pt\")\nif len(tokens_pos[0]) != len(tokens_neg[0]) and behavior_neg_prompt != \"\": ##need to even out the lengths\n    appstr = \" \" * abs(len(tokens_neg[0]) - len(tokens_pos[0]))\n    apptok = model.tokenizer.encode(appstr, return_tensors=\"pt\")\n    if len(tokens_pos[0]) > len(tokens_neg[0]):\n        tokens_neg = torch.cat((tokens_neg, apptok), dim=1)\n    else:\n        tokens_pos = torch.cat((tokens_pos, apptok), dim=1)\n\nlayers = list(range(model_numlayers))\n\naccumulated_activations_diffs = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\naccumulated_activations_pos = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\naccumulated_activations_neg = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\nlayers_positions={}\nfor layer in layers:\n    layers_positions[layer] = [list(range(len(tokens_pos[0])))]\n\nactivations = get_activations(model, tokens_pos, layers_positions, get_at=\"start\") #returns a dictionary where keys are layers and values are dicts where keys are positions and values are batchsize d-embed tensors\nfor layer, positions in activations.items():\n    for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n        accumulated_activations_diffs[layer][pos] = torch.cat([accumulated_activations_diffs[layer][pos], tensor.clone()], dim=0)\n        accumulated_activations_pos[layer][pos] = torch.cat([accumulated_activations_pos[layer][pos], tensor], dim=0)\n\nif len(tokens_neg[0])>1:\n    layers_positions = {}\n    for layer in layers:\n        layers_positions[layer] = [list(range(len(tokens_neg[0])))]\n    activations = get_activations(model, tokens_neg, layers_positions, get_at=\"start\")\n    for layer, positions in activations.items():\n        for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n            accumulated_activations_neg[layer][pos] = torch.cat([accumulated_activations_neg[layer][pos], tensor], dim=0)\n            accumulated_activations_diffs[layer][pos] -= tensor\n\nenhanced_hook_activation_to_add = {} #dictionary where keys are layers and values are lists of n_pos direction tensors\nfor layer, positions in accumulated_activations_diffs.items():\n    enhanced_hook_activation_to_add[layer] = []\n    for pos in range(len(positions)):\n        enhanced_hook_activation_to_add[layer].append(torch.mean(accumulated_activations_diffs[layer][pos], dim=0))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:18:40.132597Z","iopub.execute_input":"2024-05-26T16:18:40.133343Z","iopub.status.idle":"2024-05-26T16:18:40.371911Z","shell.execute_reply.started":"2024-05-26T16:18:40.133293Z","shell.execute_reply":"2024-05-26T16:18:40.371132Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"tokens_pos[0], tokens_neg[0], model.tokenizer.decode(tokens_pos[0]), model.tokenizer.decode(tokens_neg[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:18:59.587324Z","iopub.execute_input":"2024-05-26T16:18:59.587899Z","iopub.status.idle":"2024-05-26T16:18:59.649687Z","shell.execute_reply.started":"2024-05-26T16:18:59.587856Z","shell.execute_reply":"2024-05-26T16:18:59.648746Z"},"trusted":true},"execution_count":213,"outputs":[{"execution_count":213,"output_type":"execute_result","data":{"text/plain":"(tensor([50256, 18565,   220]),\n tensor([50256,    39,   378]),\n '<|endoftext|>Love ',\n '<|endoftext|>Hate')"},"metadata":{}}]},{"cell_type":"code","source":"torch.norm(enhanced_hook_activation_to_add[30][1])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T15:57:32.496652Z","iopub.execute_input":"2024-05-26T15:57:32.497638Z","iopub.status.idle":"2024-05-26T15:57:32.557947Z","shell.execute_reply.started":"2024-05-26T15:57:32.497591Z","shell.execute_reply":"2024-05-26T15:57:32.556986Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"tensor(222.2815)"},"metadata":{}}]},{"cell_type":"code","source":"#1-off testing: steer generation -- adding activations at the beginning of the prompt works for base model but not for chat/instruct\nprompt_to_be_steered=model.tokenizer.bos_token+\"I hate you because\"#\" What would you like to do today?\"\nmult=20\nsampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 60, \"do_sample\": True, \"repetition_penalty\": 1.1}\n\nclear_hooks(model)\nmodel.to(device)\ninputs = model.tokenizer(prompt_to_be_steered, return_tensors=\"pt\")\ninputs = {k: v.to(device) for k, v in inputs.items()}\n\ngenerated_tokens = model.generate(**inputs, **sampling_kwargs)\nprint(f\"Default output: |{model.tokenizer.decode(generated_tokens[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True, clean_up_tokenization_spaces=False)}|\")\n\nfor layer in layers:\n    layers_activations={}\n    position_dict={}\n    for i in range(len(enhanced_hook_activation_to_add[layer])):\n        position_dict[i] = (enhanced_hook_activation_to_add[layer][i] * mult).to(device)\n    #    print(f\"Layer Activation Mean: {torch.mean(position_dict[i]):.4f}\")\n    layers_activations[layer] = position_dict\n\n    generated_tokens = add_activations_and_generate(model, inputs, layers_activations, {}, sampling_kwargs, add_at=\"start\")\n    print(f\"Steered output at layer {layer}, mult: {mult}: |{model.tokenizer.decode(generated_tokens[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True, clean_up_tokenization_spaces=False)}|\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clear_hooks(model)\nprompt_to_be_steered=model.tokenizer.bos_token+\"I hate you because\"#\"What would you like to do today?\"\ninputs = model.tokenizer(prompt_to_be_steered, return_tensors=\"pt\")\ninputs = {k: v.to(device) for k, v in inputs.items()}\nlayer=6\nmult=-8\nlayers_activations={}\nposition_dict={}\nfor i in range(len(enhanced_hook_activation_to_add[layer])):\n    position_dict[i] = (enhanced_hook_activation_to_add[layer][i] * mult).to(device)\n#    print(f\"Layer Activation Mean: {torch.mean(position_dict[i]):.4f}\")\nlayers_activations[layer] = position_dict\n\nsampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 60, \"do_sample\": True, \"repetition_penalty\": 1.1}\ngenerated_tokens = add_activations_and_generate(model, inputs, layers_activations, {}, sampling_kwargs, add_at=\"start\")\nprint(f\"Prompt ={prompt_to_be_steered}, steering input ={behavior_pos_prompt}-{behavior_neg_prompt}\")\nprint(f\"Steered output at layer {layer}, mult {mult}: {model.tokenizer.decode(generated_tokens[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True, clean_up_tokenization_spaces=False)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:26:44.476406Z","iopub.execute_input":"2024-05-26T16:26:44.477220Z","iopub.status.idle":"2024-05-26T16:26:47.181783Z","shell.execute_reply.started":"2024-05-26T16:26:44.477176Z","shell.execute_reply":"2024-05-26T16:26:47.180709Z"},"trusted":true},"execution_count":229,"outputs":[{"name":"stdout","text":"Adding activations at layer 6 at position 0\ninputs[0].size=torch.Size([1, 5, 1600]), activation_vector.size=torch.Size([1600])\ninputs[0] norm: 115.8034\nAdd vector norm: 0.0000\nAdding activations at layer 6 at position 1\ninputs[0].size=torch.Size([1, 5, 1600]), activation_vector.size=torch.Size([1600])\ninputs[0] norm: 90.0670\nAdd vector norm: 590.0113\nAdding activations at layer 6 at position 2\ninputs[0].size=torch.Size([1, 5, 1600]), activation_vector.size=torch.Size([1600])\ninputs[0] norm: 88.6325\nAdd vector norm: 626.8973\nPrompt =<|endoftext|>I hate you because, steering input =<|endoftext|>Love-<|endoftext|>Hate\nSteered output at layer 6, mult -8:  you are a full-page in the Hate full-page picture in, not, Hates and his whole page. And it. A Hating in one piece at the Hain a Hating full-page on page a a big one at the Hati Hating page.\n\n\n","output_type":"stream"}]}]}